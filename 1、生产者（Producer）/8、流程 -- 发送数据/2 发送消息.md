
```java
public void run() {  
    ... // log.debug()  
  
    // main loop, runs until close is called  
    while (running) {  
        try {  
            runOnce();  
        } catch (Exception e) {  
            log.error("Uncaught error in kafka producer I/O thread: ", e);  
        }  
    }  
  
    log.debug("Beginning shutdown of Kafka producer I/O thread, sending remaining records.");  
  
    // okay we stopped accepting requests but there may still be  
    // requests in the transaction manager, accumulator or waiting for acknowledgment,    // wait until these are completed.    
    while (!forceClose && ((this.accumulator.hasUndrained() || this.client.inFlightRequestCount() > 0) || hasPendingTransactionalRequests())) {  
        try {  
            runOnce();  
        } catch (Exception e) {  
            log.error("Uncaught error in kafka producer I/O thread: ", e);  
        }  
    }  
  
    // Abort the transaction if any commit or abort didn't go through the transaction manager's queue  
    while (!forceClose && transactionManager != null && transactionManager.hasOngoingTransaction()) {  
        if (!transactionManager.isCompleting()) {  
            log.info("Aborting incomplete transaction due to shutdown");  
            transactionManager.beginAbort();  
        }  
        try {  
            runOnce();  
        } catch (Exception e) {  
            log.error("Uncaught error in kafka producer I/O thread: ", e);  
        }  
    }  
  
    if (forceClose) {  
        // We need to fail all the incomplete transactional requests and batches and wake up the threads waiting on  
        // the futures.        if (transactionManager != null) {  
            log.debug("Aborting incomplete transactional requests due to forced shutdown");  
            transactionManager.close();  
        }  
        log.debug("Aborting incomplete batches due to forced shutdown");  
        this.accumulator.abortIncompleteBatches();  
    }  
    try {  
        this.client.close();  
    } catch (Exception e) {  
        log.error("Failed to close network client", e);  
    }  
  
    log.debug("Shutdown of Kafka producer I/O thread has completed.");  
}
```

# runOnce()

```java
void runOnce() {  
    if (transactionManager != null) {  
        try {  
            transactionManager.maybeResolveSequences();  
  
            // do not continue sending if the transaction manager is in a failed state  
            if (transactionManager.hasFatalError()) {  
                RuntimeException lastError = transactionManager.lastError();  
                if (lastError != null)  
                    maybeAbortBatches(lastError);  
                client.poll(retryBackoffMs, time.milliseconds());  
                return;            }  
  
            // Check whether we need a new producerId. If so, we will enqueue an InitProducerId  
            // request which will be sent below            transactionManager.bumpIdempotentEpochAndResetIdIfNeeded();  
  
            if (maybeSendAndPollTransactionalRequest()) {  
                return;  
            }  
        } catch (AuthenticationException e) {  
            // This is already logged as error, but propagated here to perform any clean ups.  
            log.trace("Authentication exception while processing transactional request", e);  
            transactionManager.authenticationFailed(e);  
        }  
    }  
  
    long currentTimeMs = time.milliseconds();  
    long pollTimeout = sendProducerData(currentTimeMs);  
    client.poll(pollTimeout, currentTimeMs);  
}
```

# 真正发送消息

```java
private long sendProducerData(long now) {  
    Cluster cluster = metadata.fetch();  
    // get the list of partitions with data ready to send  
    RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);  
  
    // if there are any partitions whose leaders are not known yet, force metadata update  
    if (!result.unknownLeaderTopics.isEmpty()) {  
        // The set of topics with unknown leader contains topics with leader election pending as well as  
        // topics which may have expired. Add the topic again to metadata to ensure it is included        // and request metadata update, since there are messages to send to the topic.        
        for (String topic : result.unknownLeaderTopics)  
            this.metadata.add(topic, now);  
  
        log.debug("Requesting metadata update due to unknown leader topics from the batched records: {}",  
            result.unknownLeaderTopics);  
        this.metadata.requestUpdate();  
    }  
  
    // remove any nodes we aren't ready to send to  
    Iterator<Node> iter = result.readyNodes.iterator();  
    long notReadyTimeout = Long.MAX_VALUE;  
    while (iter.hasNext()) {  
        Node node = iter.next();  
        if (!this.client.ready(node, now)) {  
            // Update just the readyTimeMs of the latency stats, so that it moves forward  
            // every time the batch is ready (then the difference between readyTimeMs and            // drainTimeMs would represent how long data is waiting for the node).            this.accumulator.updateNodeLatencyStats(node.id(), now, false);  
            iter.remove();  
            notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));  
        } else {  
            // Update both readyTimeMs and drainTimeMs, this would "reset" the node  
            // latency.            this.accumulator.updateNodeLatencyStats(node.id(), now, true);  
        }  
    }  
  
    // create produce requests  
    Map<Integer, List<ProducerBatch>> batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);  
    addToInflightBatches(batches);  
    if (guaranteeMessageOrder) {  
        // Mute all the partitions drained  
        for (List<ProducerBatch> batchList : batches.values()) {  
            for (ProducerBatch batch : batchList)  
                this.accumulator.mutePartition(batch.topicPartition);  
        }  
    }  
  
    accumulator.resetNextBatchExpiryTime();  
    List<ProducerBatch> expiredInflightBatches = getExpiredInflightBatches(now);  
    List<ProducerBatch> expiredBatches = this.accumulator.expiredBatches(now);  
    expiredBatches.addAll(expiredInflightBatches);  
  
    // Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics  
    // for expired batches. see the documentation of @TransactionState.resetIdempotentProducerId to understand why    // we need to reset the producer id here.    if (!expiredBatches.isEmpty())  
        log.trace("Expired {} batches in accumulator", expiredBatches.size());  
    for (ProducerBatch expiredBatch : expiredBatches) {  
        String errorMessage = "Expiring " + expiredBatch.recordCount + " record(s) for " + expiredBatch.topicPartition  
            + ":" + (now - expiredBatch.createdMs) + " ms has passed since batch creation";  
        failBatch(expiredBatch, new TimeoutException(errorMessage), false);  
        if (transactionManager != null && expiredBatch.inRetry()) {  
            // This ensures that no new batches are drained until the current in flight batches are fully resolved.  
            transactionManager.markSequenceUnresolved(expiredBatch);  
        }  
    }  
    sensors.updateProduceRequestMetrics(batches);  
  
    // If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately  
    // loop and try sending more data. Otherwise, the timeout will be the smaller value between next batch expiry    // time, and the delay time for checking data availability. Note that the nodes may have data that isn't yet    // sendable due to lingering, backing off, etc. This specifically does not include nodes with sendable data    // that aren't ready to send since they would cause busy looping.    long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);  
    pollTimeout = Math.min(pollTimeout, this.accumulator.nextExpiryTimeMs() - now);  
    pollTimeout = Math.max(pollTimeout, 0);  
    if (!result.readyNodes.isEmpty()) {  
        log.trace("Nodes with data ready to send: {}", result.readyNodes);  
        // if some partitions are already ready to be sent, the select time would be 0;  
        // otherwise if some partition already has some data accumulated but not ready yet,        // the select time will be the time difference between now and its linger expiry time;        // otherwise the select time will be the time difference between now and the metadata expiry time;        pollTimeout = 0;  
    }  
    sendProduceRequests(batches, now);  
    return pollTimeout;  
}
```